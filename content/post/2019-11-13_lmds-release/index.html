---
title: "lmds: Landmark Multi-Dimensional Scaling"
author: rcannood
date: 2019-11-13T20:53:00+00:00
categories: ["Data mining"]
tags: ["Data mining", "Dimensionality reduction"] 
summary: "A fast dimensionality reduction method scaleable to large numbers of samples."
subtitle: "A fast dimensionality reduction method scaleable to large numbers of samples."
image:
  caption: "A dimensionality reduction obtained by lmds."
bibliography: references.bib
---



<p>Multi-dimensional scaling (MDS) <span class="citation">(Kruskal 1964)</span> is a dimensionality reduction
method used for visualising and denoising high-dimensional data. However, since MDS requires
calculating the distances between all pairs of data points, it does not scale well to datasets
with a large number of samples.</p>
<p>We released <a href="https://cran.r-project.org/package=lmds">lmds v0.1.0</a>, an implementation of
Landmark MDS (LMDS) <span class="citation">(de Silva and Tenenbaum 2004)</span>. Landmark MDS only calculates the distances between a set of landmarks
and all other data points, thereby sacrificing determinism for scalability.</p>
<div id="regular-mds" class="section level2">
<h2>Regular MDS</h2>
<p>A single-cell transcriptomics dataset is used to demonstrate the usefulness of (L)MDS.
The dataset contains 392 profiles of simulated cells, measuring the abundance levels of 2000
molecules within the cell.
Simply looking at the raw expression values as a heatmap reveals little to no information:</p>
<pre class="r"><code>library(tidyverse)
set.seed(1)

dataset &lt;- dyno::fibroblast_reprogramming_treutlein

cell_info &lt;- data.frame(grouping = dataset$grouping)

pheatmap::pheatmap(
  t(as.matrix(dataset$expression)),
  show_colnames = FALSE,
  show_rownames = FALSE,
  annotation_col = cell_info
)</code></pre>
<p><img src="/post/2019-11-13_lmds-release/index_files/figure-html/heatmap-1.png" width="672" /></p>
<p>Applying MDS quickly reveals the underlying bifurcating topology of the dataset
(from MEF to myocytes and neurons).</p>
<pre class="r"><code># compute distance matrix
dist &lt;- dynutils::calculate_distance(dataset$expression, method = &quot;pearson&quot;)
dim(dist)
## [1] 392 392

# compute MDS
dimred_mds &lt;- cmdscale(dist)

# plot points
qplot(dimred_mds[,1], dimred_mds[,2], colour = dataset$grouping) +
  theme_bw() +
  labs(x = &quot;Comp 1&quot;, y = &quot;Comp 2&quot;, colour = &quot;Group&quot;)</code></pre>
<p><img src="/post/2019-11-13_lmds-release/index_files/figure-html/mds-1.png" width="672" /></p>
<p>Regular MDS, however, requires computing all pairwise distances between data points.
This dataset only contains 392 data points, but for datasets
it is increasingly infeasible to apply MDS.</p>
</div>
<div id="landmark-mds" class="section level2">
<h2>Landmark MDS</h2>
<p>Landmark MDS (LMDS) <span class="citation">(de Silva and Tenenbaum 2004)</span> is an extension of MDS which scales much
better with respect to the number of data points in the dataset. A short while ago,
we published an R package on CRAN implementing this algorithm,
<a href="https://cran.r-project.org/package=lmds">lmds v0.1.0</a>.</p>
<p>Landmark MDS only computes the distance matrix between a set of landmarks and all other data points.
MDS is then only performed on the landmarks, and all other datapoints are projected into
the landmark space.</p>
<pre class="r"><code>library(lmds)

# compute distances between random landmarks and all data points
dist_landmarks &lt;- select_landmarks(
  dataset$expression,
  distance_method = &quot;pearson&quot;,
  num_landmarks = 150
)
dim(dist_landmarks)
## [1] 150 392

# perform LMDS
dimred_lmds &lt;- cmdscale_landmarks(dist_landmarks)

# plot points
qplot(dimred_lmds[,1], dimred_lmds[,2], colour = dataset$grouping) +
  theme_bw() +
  labs(x = &quot;Comp 1&quot;, y = &quot;Comp 2&quot;, colour = &quot;Group&quot;)</code></pre>
<p><img src="/post/2019-11-13_lmds-release/index_files/figure-html/lmds_dist-1.png" width="672" /></p>
<p>Most frequently, these two steps can be applied together as follows:</p>
<pre class="r"><code>dimred_lmds2 &lt;- lmds(
  dataset$expression,
  distance_method = &quot;pearson&quot;, 
  num_landmarks = 150
)</code></pre>
</div>
<div id="execution-time" class="section level2">
<h2>Execution time</h2>
<p>In the figure below, the execution times of MDS and LMDS are compared by increasing
the size of a random dataset until the execution of either algorithms exceeds 10 seconds.</p>
<p><img src="/post/2019-11-13_lmds-release/index_files/figure-html/timings-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>LMDS is a heuristic for MDS which scales linearly with respect to the number of points
in the dataset. Go ahead and check out our implementation for this algorithm,
available on <a href="https://cran.r-project.org/package=lmds"><code>CRAN</code></a>.
If you encounter any issues, feel free to let me know by creating an
<a href="https://github.com/dynverse/lmds/issues">issue post</a> on Github.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-de_silva_sparse_2004">
<p>de Silva, Vin, and Joshua B Tenenbaum. 2004. “Sparse Multidimensional Scaling Using Landmark Points.” <em>Technical Report, Stanford University</em>, 41.</p>
</div>
<div id="ref-kruskal_multidimensional_1964">
<p>Kruskal, J. B. 1964. “Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis.” <em>Psychometrika</em> 29 (1): 1–27. <a href="https://doi.org/10.1007/BF02289565">https://doi.org/10.1007/BF02289565</a>.</p>
</div>
</div>
</div>
