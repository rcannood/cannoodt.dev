---
title: "lmds: Landmark Multi-Dimensional Scaling"
author: rcannood
date: 2019-11-13T20:53:00+00:00
categories: ["Data mining"]
tags: ["Data mining", "Dimensionality reduction"] 
summary: "A fast dimensionality reduction method scaleable to large numbers of samples."
subtitle: "A fast dimensionality reduction method scaleable to large numbers of samples."
image:
  caption: "A dimensionality reduction obtained by lmds."
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

Multi-dimensional scaling (MDS) [@kruskal_multidimensional_1964] is a dimensionality reduction 
method used for visualising and denoising high-dimensional data. However, since MDS requires 
calculating the distances between all pairs of data points, it does not scale well to datasets 
with a large number of samples.

We released [lmds v0.1.0](https://cran.r-project.org/package=lmds), an implementation of 
Landmark MDS (LMDS) [@de_silva_sparse_2004]. Landmark MDS only calculates the distances between a set of landmarks
and all other data points, thereby sacrificing determinism for scalability.

## Regular MDS
A single-cell transcriptomics dataset is used to demonstrate the usefulness of (L)MDS.
The dataset contains 392 profiles of simulated cells, measuring the abundance levels of 2000 
molecules within the cell.
Simply looking at the raw expression values as a heatmap reveals little to no information:

```{r heatmap, message=FALSE, warning=FALSE}
library(tidyverse)
set.seed(1)

dataset <- dyno::fibroblast_reprogramming_treutlein

cell_info <- data.frame(grouping = dataset$grouping)

pheatmap::pheatmap(
  t(as.matrix(dataset$expression)),
  show_colnames = FALSE,
  show_rownames = FALSE,
  annotation_col = cell_info
)
```

Applying MDS quickly reveals the underlying bifurcating topology of the dataset 
(from MEF to myocytes and neurons). 
```{r mds}
# compute distance matrix
dist <- dynutils::calculate_distance(dataset$expression, method = "pearson")
dim(dist)

# compute MDS
dimred_mds <- cmdscale(dist)

# plot points
qplot(dimred_mds[,1], dimred_mds[,2], colour = dataset$grouping) +
  theme_bw() +
  labs(x = "Comp 1", y = "Comp 2", colour = "Group")
```

```{r thumbnail, echo=FALSE}
ggsave("featured.jpg", width = 6, height = 4)
```

Regular MDS, however, requires computing all pairwise distances between data points.
This dataset only contains `r nrow(dataset$expression)` data points, but for datasets 
it is increasingly infeasible to apply MDS. 

## Landmark MDS
Landmark MDS (LMDS) [@de_silva_sparse_2004] is an extension of MDS which scales much
better with respect to the number of data points in the dataset. A short while ago,
we published an R package on CRAN implementing this algorithm, 
[lmds v0.1.0](https://cran.r-project.org/package=lmds).

Landmark MDS only computes the distance matrix between a set of landmarks and all other data points.
MDS is then only performed on the landmarks, and all other datapoints are projected into
the landmark space.
```{r lmds_dist}
library(lmds)

# compute distances between random landmarks and all data points
dist_landmarks <- select_landmarks(
  dataset$expression,
  distance_method = "pearson",
  num_landmarks = 150
)
dim(dist_landmarks)

# perform LMDS
dimred_lmds <- cmdscale_landmarks(dist_landmarks)

# plot points
qplot(dimred_lmds[,1], dimred_lmds[,2], colour = dataset$grouping) +
  theme_bw() +
  labs(x = "Comp 1", y = "Comp 2", colour = "Group")
```

Most frequently, these two steps can be applied together as follows:
```{r shorthand}
dimred_lmds2 <- lmds(
  dataset$expression,
  distance_method = "pearson", 
  num_landmarks = 150
)
```

## Execution time

In the figure below, the execution times of MDS and LMDS are compared by increasing 
the size of a random dataset until the execution of either algorithms exceeds 10 seconds.

```{r timings, echo=FALSE, eval=F}
largex <- Matrix::rsparsematrix(nrow = 100000, ncol = 10000, density = .01)

log <- list()
num_samples <- 100
time <- 0
while (time < 10) {
  subx <- largex[seq_len(num_samples),]
  time <- system.time({
    dimred <- lmds(subx)
  })[["user.self"]]
  log[[length(log) + 1]] <- tibble(method = "lmds()", num_samples, time)
  num_samples <- num_samples * 1.5
}

num_samples <- 100
time <- 0
while (time < 10) {
  subx <- largex[seq_len(num_samples),]
  time <- system.time({
    dist <- dist(subx)
    dimred <- cmdscale(dist)
  })[["user.self"]]
  log[[length(log) + 1]] <- tibble(method = "cmdscale()", num_samples, time)
  num_samples <- num_samples * 1.5
}

logdf <- bind_rows(log)

ggplot(logdf, aes(num_samples, time, colour = method)) +
  geom_point() +
  geom_line() +
  theme_classic() +
  labs(
    x = "Number of data points",
    y = "Execution time (seconds)",
    colour = "Method",
    title = "A comparison of the execution times of MDS and LMDS\non a dataset with 10'000 features and increasing numbers of data points."
  ) +
  scale_x_log10(limits = c(100, 100000))
```

## Conclusion

LMDS is a heuristic for MDS which scales linearly with respect to the number of points
in the dataset. Go ahead and check out our implementation for this algorithm,
available on [`CRAN`](https://cran.r-project.org/package=lmds).
If you encounter any issues, feel free to let me know by creating an 
[issue post](https://github.com/dynverse/lmds/issues) on Github.