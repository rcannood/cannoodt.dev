---
title: "lmds: Landmark Multi-Dimensional Scaling"
author: rcannood
date: 2019-11-26T13:53:00+00:00
categories: ["Data mining"]
tags: ["Data mining", "Dimensionality reduction", "R"]
summary: "A fast dimensionality reduction method scaleable to large numbers of samples."
subtitle: "A fast dimensionality reduction method scaleable to large numbers of samples."
image:
  caption: "A dimensionality reduction obtained by lmds."
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

Multi-dimensional scaling (MDS) [@kruskal_multidimensional_1964] is a dimensionality reduction
method used for visualising and denoising high-dimensional data. However, since MDS requires 
calculating the distances between all pairs of data points, it does not scale well to datasets 
with a large number of samples.

We released [lmds v0.1.0](https://cran.r-project.org/package=lmds), an implementation of 
Landmark MDS (LMDS) [@de_silva_sparse_2004]. Landmark MDS only calculates the distances between a set of landmarks
and all other data points, thereby sacrificing determinism for scalability.

## Regular MDS
A single-cell transcriptomics dataset [@treutlein_dissectingdirectreprogramming_2016] is used to demonstrate (L)MDS, 
containing 392 profiles which measure the abundance levels of 2000 different molecules within individual cells.
Note that while the dataset is thus only a 392Ã—2000 matrix, LMDS is designed to scale to much higher dimensionality, as demonstrated in the last section.

Simply looking at the raw expression values as a heatmap reveals little to no information:

```{r heatmap, message=FALSE, warning=FALSE}
library(tidyverse)
set.seed(1)

dataset <- dyno::fibroblast_reprogramming_treutlein

cell_info <- data.frame(grouping = dataset$grouping)

pheatmap::pheatmap(
  t(as.matrix(dataset$expression)),
  show_colnames = FALSE,
  show_rownames = FALSE,
  annotation_col = cell_info
)
```

Applying MDS quickly reveals the underlying bifurcating topology of the dataset 
(from MEF to myocytes and neurons). 
```{r mds}
# compute distance matrix
dist <- dynutils::calculate_distance(dataset$expression, method = "pearson")
dim(dist)

# compute MDS
dimred_mds <- cmdscale(dist)

# plot points
qplot(dimred_mds[,1], dimred_mds[,2], colour = dataset$grouping) +
  theme_bw() +
  labs(x = "Comp 1", y = "Comp 2", colour = "Group")
```

```{r thumbnail, echo=FALSE}
ggsave("featured.jpg", width = 6, height = 4)
```

Regular MDS, however, requires computing all pairwise distances between data points.
This dataset only contains `r nrow(dataset$expression)` data points, but for datasets 
it is increasingly infeasible to apply MDS. 

## Landmark MDS
Landmark MDS (LMDS) [@de_silva_sparse_2004] is an extension of MDS which scales much
better with respect to the number of data points in the dataset. A short while ago,
we published an R package on CRAN implementing this algorithm, 
[lmds v0.1.0](https://cran.r-project.org/package=lmds).

Landmark MDS only computes the distance matrix between a set of landmarks and all other data points.
MDS is then only performed on the landmarks, and all other datapoints are projected into
the landmark space.
```{r lmds_dist}
library(lmds)

# compute distances between random landmarks and all data points
dist_landmarks <- select_landmarks(
  dataset$expression,
  distance_method = "pearson",
  num_landmarks = 150
)
dim(dist_landmarks)

# perform LMDS
dimred_lmds <- cmdscale_landmarks(dist_landmarks)

# plot points
qplot(dimred_lmds[,1], dimred_lmds[,2], colour = dataset$grouping) +
  theme_bw() +
  labs(x = "Comp 1", y = "Comp 2", colour = "Group")
```

Most frequently, these two steps can be applied together as follows:
```{r shorthand}
dimred_lmds2 <- lmds(
  dataset$expression,
  distance_method = "pearson", 
  num_landmarks = 150
)
```

## Execution time

In the figure below, the execution times of MDS and LMDS are compared by increasing 
the size of a random dataset until the execution of either algorithms exceeds 10 seconds.

```{r timings, echo=FALSE, eval=TRUE}
largex <- Matrix::rsparsematrix(nrow = 100000, ncol = 10000, density = .01)
 
log <- list()
num_samples <- 100
time <- 0
while (time < 10) {
  subx <- largex[seq_len(num_samples),]
  time <- system.time({
    dimred <- lmds(subx)
  })[["elapsed"]]
  log[[length(log) + 1]] <- tibble(method = "lmds()", num_samples, time)
  num_samples <- num_samples * 1.5
}
 
num_samples <- 100
time <- 0
while (time < 10) {
  subx <- largex[seq_len(num_samples),]
  time <- system.time({
    dist <- dist(subx)
    dimred <- cmdscale(dist)
  })[["elapsed"]]
  log[[length(log) + 1]] <- tibble(method = "cmdscale()", num_samples, time)
  num_samples <- num_samples * 1.5
}

logdf <- bind_rows(log)

ggplot(logdf, aes(num_samples, time, colour = method)) +
  geom_point() +
  geom_line() +
  theme_classic() +
  labs(
    x = "Number of data points",
    y = "Execution time (seconds)",
    colour = "Method",
    title = "A comparison of the execution times of MDS and LMDS\non a dataset with 10'000 features and increasing numbers of data points."
  ) +
  scale_x_log10(limits = c(100, 100000))
```

## Conclusion

LMDS is a heuristic for MDS which scales linearly with respect to the number of points
in the dataset. Go ahead and check out our implementation for this algorithm,
available on [`CRAN`](https://cran.r-project.org/package=lmds).
If you encounter any issues, feel free to let me know by creating an 
[issue post](https://github.com/dynverse/lmds/issues) on Github.

## References