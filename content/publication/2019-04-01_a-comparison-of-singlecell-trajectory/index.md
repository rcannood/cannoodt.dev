---
abstract: In computational biology and other sciences, researchers are frequently faced with a choice between several computational methods for performing data analyses. Benchmarking studies aim to rigorously compare the performance of different methods using well-characterized benchmark datasets, to determine the strengths of each method or to provide recommendations regarding suitable choices of methods for an analysis. However, benchmarking studies must be carefully designed and implemented to provide accurate, unbiased, and informative results. Here, we summarize key practical guidelines and recommendations for performing high-quality benchmarking analyses, based on our experiences in computational biology.
authors:
- Wouter Saelens*
- <b>Robrecht Cannoodt</b>*
- Helena Todorov
- Yvan Saeys
date: "2019-04-01T00:00:00Z"
doi: "10.1038/s41587-019-0071-9"
featured: true
image:
  caption: 'A 3D rendering of our benchmark results.'
  focal_point: ""
  preview_only: false
projects: []
publication: 'Nature Biotechnology'
publication_short: ""
publication_types:
- "2"
publishDate: "2019-04-01T00:00:00Z"
# slides: example
summary: Unsure which trajectory inference method to use for your single-cell dataset? Our benchmarking effort sheds light on this matter.
# tags:
# - Source Themes
title: A comparison of single-cell trajectory inference methods
url_code: "https://github.com/dynverse/dynbenchmark"
url_dataset: "https://doi.org/10.5281/zenodo.1443566"
# url_pdf: https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-019-1738-8
# url_poster: ""
# url_project: ""
# url_slides: ""
# url_source: ""
# url_video: ""
---
